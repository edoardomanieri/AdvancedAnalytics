{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import udf, struct, array, col, lit\n",
    "from pyspark.sql.types import StringType\n",
    "from datetime import datetime\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from difflib import unified_diff\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from itertools import chain\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/edoardo/Desktop/University/KU Leuven/Advancedanalytics/ThirdAssignment/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class StreamingThread(Thread):\n",
    "    def __init__(self, ssc):\n",
    "        Thread.__init__(self)\n",
    "        self.ssc = ssc\n",
    "    def run(self):\n",
    "        ssc.start()\n",
    "        ssc.awaitTermination()\n",
    "    def stop(self):\n",
    "        print('----- Stopping... this may take a few seconds -----')\n",
    "        self.ssc.stop(stopSparkContext=False, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_diff(old, new):\n",
    "    return '\\n'.join([ l for l in unified_diff(old.split('\\n'), new.split('\\n')) if l.startswith('+') or l.startswith('-') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()['models_loaded'] = False\n",
    "\n",
    "\n",
    "def process(time, rdd):\n",
    "    if rdd.isEmpty():\n",
    "        return\n",
    "    \n",
    "    print(\"========= %s =========\" % str(time))\n",
    "    \n",
    "    # Convert to data frame\n",
    "    df = spark.read.json(rdd)\n",
    "    \n",
    "    # preprocessing\n",
    "    diff_udf = F.udf(make_diff, StringType())\n",
    "    df_withdiff = df.withColumn(\"diff\", diff_udf(F.col(\"text_old\"), F.col(\"text_new\")))\n",
    "    df_withip = df_withdiff.withColumn(\"ip\", F.when((F.size(F.split(F.col(\"name_user\"), r\"\\.\")) - 1) == 4, 1)\n",
    "                                               .when((F.size(F.split(F.col(\"name_user\"), r\"\\:\")) - 1) == 7, 1)\n",
    "                                               .otherwise(0))\n",
    "    df_nanComment = df_withip.withColumn(\"nan_comment\", F.when(F.isnan(F.col(\"comment\")) | F.isnull(F.col(\"comment\")), 1)\n",
    "                                            .otherwise(0))\n",
    "    df = df_nanComment.select(['diff', 'ip', 'nan_comment', 'label'])\n",
    "    \n",
    "    if not globals()['models_loaded']:\n",
    "        # load in your models here\n",
    "        globals()['my_model'] = PipelineModel.load(f\"{path}/pipelineModel\")\n",
    "        globals()['models_loaded'] = True\n",
    "        \n",
    "    # And then predict using the loaded model: \n",
    "    df_result = globals()['my_model'].transform(df)\n",
    "    meta = [f.metadata for f in df_result.schema.fields if f.name == \"newlabel\"]\n",
    "    repl_dict = dict(enumerate(meta[0][\"ml_attr\"][\"vals\"]))\n",
    "    mapping_expr = create_map([lit(x) for x in chain(*repl_dict.items())])\n",
    "    df_result = df_result.withColumn('prediction', mapping_expr[df_result['prediction']])\n",
    "    df_result.select(['label','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"seppe.net\", 7778)\n",
    "lines.foreachRDD(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= 2020-04-24 15:11:20 =========\n",
      "+------+----------+\n",
      "| label|prediction|\n",
      "+------+----------+\n",
      "|  safe|      safe|\n",
      "|unsafe|      safe|\n",
      "|  safe|      safe|\n",
      "+------+----------+\n",
      "\n",
      "========= 2020-04-24 15:11:30 =========\n",
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "| safe|      safe|\n",
      "| safe|      safe|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t = StreamingThread(ssc)\n",
    "ssc_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Stopping... this may take a few seconds -----\n",
      "========= 2020-04-24 15:11:40 =========\n",
      "+------+----------+\n",
      "| label|prediction|\n",
      "+------+----------+\n",
      "|unsafe|      safe|\n",
      "|  safe|      safe|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc_t.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bita745f45eeba44309b7e466b46e841053"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
